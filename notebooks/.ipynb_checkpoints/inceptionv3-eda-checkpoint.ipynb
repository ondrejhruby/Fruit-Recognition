{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Check for TensorFlow GPU access\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "# See TensorFlow version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../data/fruits-360/'\n",
    "test_dir = os.path.join(base_dir, 'Test')\n",
    "train_dir = os.path.join(base_dir, 'Training')\n",
    "\n",
    "train_dir = pathlib.Path(train_dir)\n",
    "test_dir = pathlib.Path(test_dir) \n",
    "\n",
    "#Img size\n",
    "\n",
    "img_height = 299\n",
    "img_width = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing - ImageDataGenerator\n",
    "\n",
    "# Normalize the pixels in the train data images, resize and augment the data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,# Image augmentaion \n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2, # Zoom in on image by 20%\n",
    "    horizontal_flip=True, #  Flip the image horizontally\n",
    "    validation_split=0.2\n",
    "    ) # Split 20% of the data for validation\n",
    "\n",
    "# Normalize the test data images\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) \n",
    "\n",
    "#flow_from_directory takes the directory containing the images, target size, \n",
    "# batch size, class mode as parameters\n",
    "\n",
    "#Preprocess the training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical',\n",
    "    subset='training') # Set as training data\n",
    "\n",
    "#Preprocess the validation data\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, # Same directory as training data\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation') # Set as validation data\n",
    "\n",
    "#Preprocess the testing data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 13 clases - 10% of the data\n",
    "\n",
    "# Data preprocessing - ImageDataGenerator\n",
    "\n",
    "# Normalize the pixels in the train data images, resize and augment the data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,# Image augmentaion \n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2, # Zoom in on image by 20%\n",
    "    horizontal_flip=True, #  Flip the image horizontally\n",
    "    validation_split=0.2) # Split 20% of the data for validation\n",
    "\n",
    "# Normalize the test data images\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) \n",
    "#flow_from_directory takes the directory containing the images, target size, \n",
    "# batch size, class mode as parameters\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    classes=['Apple Red 2', 'Avocado', 'Banana', 'Cherry 2', 'Kiwi', 'Lemon', 'Mandarine', 'Peach', 'Pineapple', 'Raspberry', 'Strawberry', 'Tomato 1', 'Watermelon'],\n",
    "    class_mode='categorical',\n",
    "    subset='training') # Set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, # Same directory as training data\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    classes=['Apple Red 2', 'Avocado', 'Banana', 'Cherry 2', 'Kiwi', 'Lemon', 'Mandarine', 'Peach', 'Pineapple', 'Raspberry', 'Strawberry', 'Tomato 1', 'Watermelon'],\n",
    "    class_mode='categorical',\n",
    "    subset='validation') # Set as validation data\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    classes=['Apple Red 2', 'Avocado', 'Banana', 'Cherry 2', 'Kiwi', 'Lemon', 'Mandarine', 'Peach', 'Pineapple', 'Raspberry', 'Strawberry', 'Tomato 1', 'Watermelon'],\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model based on the InceptionV3 architecture\n",
    "\n",
    "# InceptionV3 model and use the weights from imagenet\n",
    "conv_base = keras.applications.InceptionV3(\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_shape=(img_height, img_width, 3)\n",
    ")\n",
    "\n",
    "conv_base.trainable = False # Freeze the base model layers\n",
    "\n",
    "InceptionV3_model = conv_base.output\n",
    "pool = GlobalAveragePooling2D()(InceptionV3_model)\n",
    "dense_1 = layers.Dense(512, activation = 'relu')(pool)\n",
    "output = layers.Dense(131, activation = 'softmax')(dense_1)\n",
    "\n",
    "# Create an example of the Archictecture to plot on a graph\n",
    "model_inception = models.Model(inputs=conv_base.input, outputs=output)\n",
    "\n",
    "model_inception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_inception.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "    history = model_inception.fit(\n",
    "        train_generator,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        verbose = 1,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)])\n",
    "    \n",
    "# Save the model\n",
    "def save_model(model, seed):\n",
    "    model.save(f\"../models/inceptionv3-{seed}\")\n",
    "    \n",
    "save_model(model_inception, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "\n",
    "loss, accuracy = model_inception.evaluate(test_generator)\n",
    "print(f'Test accuracy: {accuracy:.3f}, Test loss: {loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inception = keras.models.load_model('../models/inceptionv3-4')\n",
    "class_dict = test_generator.class_indices # a dictionary of the form class name: class index\n",
    "\n",
    "#model_inception = keras.models.load_model('../models/inceptionv3-3-13classes')\n",
    "#class_dict = test_generator.class_indices # a dictionary of the form class name: class index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# with open('class_names.json', 'w') as f:\n",
    "#    json.dump(class_dict, f)\n",
    "\n",
    "def classify(img_path):    \n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "        \n",
    "    img_array = image.img_to_array(img)\n",
    "\n",
    "    img_batch = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    img_preprocessed = preprocess_input(img_batch)\n",
    "    \n",
    "    prediction = model_inception.predict(img_preprocessed)\n",
    "\n",
    "    return prediction\n",
    "\n",
    "pred = classify('../random-image-test/kiwi_white.png')\n",
    "\n",
    "score = tf.nn.softmax(pred[0])\n",
    "\n",
    "klass = [k for k, v in class_dict.items() if v == np.argmax(score)][0]\n",
    "\n",
    "print(f'Predicted class: {klass}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(1, len(history.history['accuracy']) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.savefig('../images/inceptionv3-4-1-Accuracy.png')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.savefig('../images/inceptionv3-4-2-Loss.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
