{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bff6ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 11:40:26.852313: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Model\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Check for TensorFlow GPU access\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "# See TensorFlow version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0a65954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set directory for training and testing data\n",
    "base_dir = '../data/fruits-360/'\n",
    "test_dir = os.path.join(base_dir, 'Test')\n",
    "train_dir = os.path.join(base_dir, 'Training')\n",
    "\n",
    "train_dir = pathlib.Path(train_dir)\n",
    "test_dir = pathlib.Path(test_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4002b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Img size\n",
    "\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32a3a3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54190 images belonging to 131 classes.\n",
      "Found 13502 images belonging to 131 classes.\n",
      "Found 22688 images belonging to 131 classes.\n"
     ]
    }
   ],
   "source": [
    "# VGG16 Model \n",
    "\n",
    "# Data preprocessing - ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,# Image augmentaion \n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2, # Zoom in on image by 20%\n",
    "    horizontal_flip=True, #  Flip the image horizontally\n",
    "    validation_split=0.2) # Split 20% of the data for validation\n",
    "\n",
    "# Normalize the test data images\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) \n",
    "#flow_from_directory takes the directory containing the images, target size, \n",
    "# batch size, class mode as parameters\n",
    "\n",
    "#Preprocess the training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical',\n",
    "    subset='training') # Set as training data\n",
    "\n",
    "#Preprocess validation data\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, # Same directory as training data\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation') # Set as validation data\n",
    "\n",
    "#Preprocess testing data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b72765ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 11:41:05.325781: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 131)               67203     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,781,891\n",
      "Trainable params: 67,203\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ondrahruby/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create the model based on VGG16\n",
    "\n",
    "base_model = tf.keras.applications.VGG16(include_top=False,\n",
    "                                    weights=\"imagenet\",\n",
    "                                    input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Freeze the layers (layers not updated during training)\n",
    "base_model.trainable = False\n",
    "\n",
    "Vgg = base_model.output\n",
    "#Compute average of the feature maps along the last 2 dimensions\n",
    "Vgg = GlobalAveragePooling2D()(Vgg)\n",
    "#Vgg = Dropout(0.20)(Vgg)\n",
    "predictions = Dense(131, activation= 'softmax')(Vgg)\n",
    "Vgg = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "opt = Adam(lr=0.01)\n",
    "Vgg.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "Vgg.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d317329c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1694/1694 [==============================] - 11512s 7s/step - loss: 1.3111 - accuracy: 0.7530 - val_loss: 0.5574 - val_accuracy: 0.8962\n",
      "Epoch 2/10\n",
      " 756/1694 [============>.................] - ETA: 1:16:53 - loss: 0.3571 - accuracy: 0.9454"
     ]
    }
   ],
   "source": [
    "\n",
    "# patience 3 = training will stop after 3 epochs if the loss doesn't improve\n",
    "history = Vgg.fit(\n",
    "        train_generator,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        verbose = 1,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ab439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model VGG\n",
    "def save_model(model, seed):\n",
    "    model.save(f\"../models/vgg16v1-{seed}\")\n",
    "    \n",
    "save_model(Vgg, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a0f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "\n",
    "loss, accuracy = Vgg.evaluate(test_generator)\n",
    "print(f'Test accuracy: {accuracy:.3f}, Test loss: {loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06f10a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(history.history[\"acc\"])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76adad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
